---
layout: post
title: Building Text to SQL LLM Agents
date: 2025-01-22 20:19:00
description: In this post we explore how we can leverage contemporary LLMs to formulate and run SQL queries prompted in human language
tags: agents llms sql
categories: llm-agents
featured: true
---

Recently, I started exporing how to leverage Large Language Models (LLMs) to automate _SQL_ query formulation. If you think about it, crafting an efficient database query requires a non-trivial amount of knowledge, such as understanding [relational algebra](https://en.wikipedia.org/wiki/Relational_algebra), [SQL](https://en.wikipedia.org/wiki/SQL), [indices](https://en.wikipedia.org/wiki/Database_index), etc.

On top of that, you need to be familiarized with the intricacies of the data model encoded in the schema in order to articulate a SQL statement designed to fetch data in its desired shape out of a database: A question that can be articulately clearly and relatively easily in a natural language could require fetching, filtering and aggregating information broken down among several tables.

Knowing SQL is expected if you are a software developer, DBA or data scientist. But if you're a scholar, researcher, business person or other type of decision maker, SQL may not necessarily be part of your wheelhouse. This doesn't mean at all that you won't need to deal with databases, but realying on someone else or learning the language is another hurdle in your way.

## Leveraging LLMs for writing SQL code

Large Language Models shine (among many other things) at writing programming languages and SQL is no exeption. Naturally, we can _ask_ an LLM to write the SQL code that fetches the information we need. In the remainder of this post, we explore two flavors to achieve this goal, and then discuss some lesons learnt along the way. I took inspiration from [this](https://huggingface.co/docs/smolagents/en/examples/text_to_sql) demo from `smolagents`, and built upon it by using a non-trivial database and testing some useful variations (at least to me ðŸ˜…).

### A database of scientific articles

As our testing grounds we will use a relatively simple database with the catalog of [PMC Open Access](https://pmc.ncbi.nlm.nih.gov/tools/openftlist/). PMC OA contains full text articles or research in the life sciences and as of writing, it contains _6.5 million_ articles. We will not work with the full texts, only with the [catalog](https://ftp.ncbi.nlm.nih.gov/pub/pmc/oa_file_list.csv).

Using [SQLModel](https://sqlmodel.tiangolo.com) the following model classes represent the schema of our database.

```python
from typing import Optional
from sqlmodel import SQLModel, Field
from datetime import datetime

class Article(SQLModel, table=True):
	id:Optional[int] = Field(default=None, primary_key=True)
	path:str
	pmcid:str
	pmid:str
	last_updated:datetime
	# Publication information
	journal_id:Optional[int] = Field(foreign_key="journal.id")
	year:Optional[int]
	month:Optional[str]
	day:Optional[int]
	volume:Optional[int]
	issue:Optional[int]
	eaccession:Optional[str]
	license_id:int | None = Field(foreign_key="license.id")
	retracted:bool = Field(default=False)

class License(SQLModel, table=True):
	id:Optional[int] = Field(default=None, primary_key=True)
	name:str

class Journal(SQLModel, table=True):
	id:Optional[int] = Field(default=None, primary_key=True)
	commercial:bool | None = Field(default=False)
	name:str
```

The centerpiece of the database is the `Article` table, which contains articles' metadata, such as its path in the repository, identifiers, publicaiton date, etc. Tables `License` and `Journal` are the result of the normalization of the data contained within the original `.csv` file.

The repository contains code to download the data files and build a [SQLite](https://www.sqlite.org) database using these models. For your convenience, you can also download the database file from [here](#) (it is a large download).

## Prompting an LLM with schema information

Modern LLMs are trained to [_follow instructions_](https://arxiv.org/abs/2203.02155) respond well to commands. The key insight is to **seed a description of the schema into the prompt**. One method commonly used for this purpose is using the _system message_ to condition the LLM to behave in certain specific way. In the following example, we create an llm _chain_ [Llama 3.1 Instruct](https://huggingface.co/meta-llama/Llama-3.1-70B-Instruct)
